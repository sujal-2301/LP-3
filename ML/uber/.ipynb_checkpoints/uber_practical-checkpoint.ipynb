{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6387be53",
   "metadata": {},
   "source": [
    "# Uber Trips — College Practical (EDA + Cleaning + Simple Model)\n",
    "\n",
    "This notebook loads **`uber.csv`**, performs **EDA**, **data cleaning**, **feature engineering** (Haversine distance), builds visualizations, and trains a **Linear Regression** model to predict fare.\n",
    "\n",
    "**What you'll get**\n",
    "- Cleaned dataset with features\n",
    "- Descriptive statistics\n",
    "- Plots (hour, day-of-week, daily trend, fare & distance histograms, fare vs distance scatter)\n",
    "- Model metrics (R², MAE) and coefficients\n",
    "\n",
    "> Tip: Run cells from top to bottom. Replace the CSV path in the next cell if your file name is different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251274ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install libraries (uncomment if your environment doesn't have them)\n",
    "# %pip install -q pandas numpy matplotlib scikit-learn\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Notebook options\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecebd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "CSV_PATH = 'uber.csv'   # <-- change if your filename is different\n",
    "PLOTS_DIR = Path('plots')\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_dataset(csv_path: str, sample: int = None) -> pd.DataFrame:\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, sep=None, engine='python', low_memory=False)\n",
    "    except Exception:\n",
    "        df = pd.read_csv(csv_path, low_memory=False)\n",
    "    # Drop unnamed index-like columns\n",
    "    for c in list(df.columns):\n",
    "        if c.lower().startswith('unnamed'):\n",
    "            df = df.drop(columns=[c])\n",
    "    if sample is not None and len(df) > sample:\n",
    "        df = df.sample(n=sample, random_state=42)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Vectorized Haversine distance in kilometers.\"\"\"\n",
    "    R = 6371.0\n",
    "    lat1 = np.radians(lat1.astype(float))\n",
    "    lon1 = np.radians(lon1.astype(float))\n",
    "    lat2 = np.radians(lat2.astype(float))\n",
    "    lon2 = np.radians(lon2.astype(float))\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def plot_and_save(series_or_df, kind, title, xlabel, ylabel, filename: str):\n",
    "    \"\"\"One chart per figure, Matplotlib only, no explicit colors.\"\"\"\n",
    "    plt.figure()\n",
    "    if kind == 'bar':\n",
    "        series_or_df.plot(kind='bar')\n",
    "    elif kind == 'line':\n",
    "        series_or_df.plot(kind='line')\n",
    "    elif kind == 'hist':\n",
    "        series_or_df.plot(kind='hist', bins=50)\n",
    "    elif kind == 'scatter':\n",
    "        plt.scatter(series_or_df.iloc[:,0], series_or_df.iloc[:,1], s=5)\n",
    "    else:\n",
    "        raise ValueError('Unsupported plot kind')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    out_path = PLOTS_DIR / filename\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25922b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(CSV_PATH, sample=120000)  # sample to keep things snappy\n",
    "print(f'Rows: {len(df)} | Columns: {len(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36600570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and parse a datetime-like column (prefer 'pickup_datetime')\n",
    "dt_col = None\n",
    "candidates = ['pickup_datetime', 'date_time', 'datetime', 'timestamp', 'date/time', 'date', 'time']\n",
    "for cand in candidates:\n",
    "    for c in df.columns:\n",
    "        if c.lower() == cand.lower():\n",
    "            dt_col = c; break\n",
    "    if dt_col: break\n",
    "if dt_col is None:\n",
    "    # fuzzy pickup time\n",
    "    for c in df.columns:\n",
    "        if 'pickup' in c.lower() and 'time' in c.lower():\n",
    "            dt_col = c; break\n",
    "\n",
    "if dt_col is None:\n",
    "    raise ValueError(\"No datetime-like column found (e.g., 'pickup_datetime'). Found columns: \" + ', '.join(df.columns))\n",
    "\n",
    "df['pickup_datetime'] = pd.to_datetime(df[dt_col], errors='coerce', infer_datetime_format=True)\n",
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "df['day_of_week'] = df['pickup_datetime'].dt.day_name()\n",
    "df['date'] = df['pickup_datetime'].dt.date\n",
    "\n",
    "df[['pickup_datetime','hour','day_of_week','date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep essential columns if present; drop nulls & obvious outliers\n",
    "required = ['fare_amount','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count','pickup_datetime']\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f'Missing required columns: {missing}')\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=required)\n",
    "\n",
    "# NYC-ish bounds (guards against swapped coords too)\n",
    "lat_ok = df['pickup_latitude'].between(40.0, 42.0) & df['dropoff_latitude'].between(40.0, 42.0)\n",
    "lon_ok = df['pickup_longitude'].between(-75.0, -72.0) & df['dropoff_longitude'].between(-75.0, -72.0)\n",
    "df = df[lat_ok & lon_ok]\n",
    "\n",
    "# Reasonable passenger count\n",
    "df = df[(df['passenger_count'] >= 1) & (df['passenger_count'] <= 6)]\n",
    "\n",
    "# Positive, reasonable fares\n",
    "df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 300)]\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f'Cleaning reduced rows from {before} -> {after}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_km'] = haversine_km(\n",
    "    df['pickup_latitude'], df['pickup_longitude'],\n",
    "    df['dropoff_latitude'], df['dropoff_longitude']\n",
    ")\n",
    "# Remove tiny/insane distances\n",
    "before = len(df)\n",
    "df = df[(df['distance_km'] > 0.05) & (df['distance_km'] < 100)].reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f'Feature engineering filtered rows: {before} -> {after}')\n",
    "df[['fare_amount','distance_km','hour','passenger_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aac752",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.describe(include='all', datetime_is_numeric=True)\n",
    "summary_path = Path('summary.csv')\n",
    "summary.to_csv(summary_path, index=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trips by hour\n",
    "hour_counts = df['hour'].value_counts().sort_index()\n",
    "plot_and_save(hour_counts, 'bar', 'Trips by Hour of Day', 'Hour', 'Trips', 'trips_by_hour.png')\n",
    "\n",
    "# Trips by day of week (Mon..Sun order)\n",
    "order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "dow_counts = df['day_of_week'].value_counts().reindex(order)\n",
    "plot_and_save(dow_counts, 'bar', 'Trips by Day of Week', 'Day', 'Trips', 'trips_by_dow.png')\n",
    "\n",
    "# Daily trend\n",
    "daily = df.groupby('date').size()\n",
    "plot_and_save(daily, 'line', 'Daily Trip Counts', 'Date', 'Trips', 'daily_trips.png')\n",
    "\n",
    "# Fare histogram\n",
    "plot_and_save(df['fare_amount'], 'hist', 'Fare Amount Distribution', 'Fare ($)', 'Frequency', 'fare_hist.png')\n",
    "\n",
    "# Distance histogram\n",
    "plot_and_save(df['distance_km'], 'hist', 'Trip Distance Distribution', 'Distance (km)', 'Frequency', 'distance_hist.png')\n",
    "\n",
    "# Fare vs Distance scatter (sample)\n",
    "small = df.sample(n=min(20000, len(df)), random_state=42)[['distance_km','fare_amount']]\n",
    "plot_and_save(small, 'scatter', 'Fare vs Distance (sample)', 'Distance (km)', 'Fare ($)', 'fare_vs_distance_scatter.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression: fare ~ distance_km + hour + passenger_count\n",
    "features = ['distance_km','hour','passenger_count']\n",
    "X = df[features].astype(float).values\n",
    "y = df['fare_amount'].astype(float).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tr = model.predict(X_train)\n",
    "y_pred_te = model.predict(X_test)\n",
    "\n",
    "metrics = {\n",
    "    'train_r2': float(r2_score(y_train, y_pred_tr)),\n",
    "    'test_r2': float(r2_score(y_test, y_pred_te)),\n",
    "    'test_mae': float(mean_absolute_error(y_test, y_pred_te)),\n",
    "    'coef_distance_km': float(model.coef_[0]),\n",
    "    'coef_hour': float(model.coef_[1]),\n",
    "    'coef_passenger_count': float(model.coef_[2]),\n",
    "    'intercept': float(model.intercept_),\n",
    "    'n_train': int(len(y_train)),\n",
    "    'n_test': int(len(y_test))\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2483901",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv = Path('uber_clean_features.csv')\n",
    "df.to_csv(out_csv, index=False)\n",
    "print('Saved cleaned dataset with features to:', out_csv.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb9003",
   "metadata": {},
   "source": [
    "## Next Steps (optional)\n",
    "- Try **Regularized** models (Ridge/Lasso) or **Tree-based** models.\n",
    "- Add **rush-hour** flags, **month/season** dummies.\n",
    "- Clip or transform fares (e.g., log) and compare metrics.\n",
    "- Evaluate with **R²**, **MAE**, and **Residual plots**.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
